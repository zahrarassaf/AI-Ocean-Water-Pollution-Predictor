import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (accuracy_score, classification_report, 
                           confusion_matrix, roc_curve, auc, roc_auc_score)
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("OCEAN WATER POLLUTION PREDICTION MODEL")
print("=" * 60)

class OceanPollutionModel:
    def __init__(self):
        self.models = {}
        self.scaler = StandardScaler()
        self.best_model = None
        self.feature_importance = None
        
    def load_data(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        print("\nğŸ“Š Loading data...")
        
        try:
            self.X_train = pd.read_csv("data/processed/X_train.csv")
            self.X_test = pd.read_csv("data/processed/X_test.csv")
            self.y_train = pd.read_csv("data/processed/y_train.csv").squeeze()
            self.y_test = pd.read_csv("data/processed/y_test.csv").squeeze()
            
            print(f"âœ… Data loaded successfully!")
            print(f"   Training set: {self.X_train.shape}")
            print(f"   Test set: {self.X_test.shape}")
            print(f"   Features: {list(self.X_train.columns)}")
            
            # Ù†Ù…Ø§ÛŒØ´ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
            print(f"\nğŸ“ˆ Class distribution:")
            train_counts = self.y_train.value_counts().sort_index()
            test_counts = self.y_test.value_counts().sort_index()
            
            for label in [0, 1, 2]:
                print(f"   Class {label} (Low/Med/High): Train={train_counts.get(label, 0)}, Test={test_counts.get(label, 0)}")
            
            return True
            
        except FileNotFoundError as e:
            print(f"âŒ Error loading data: {e}")
            print("Please run process_data.py first")
            return False
    
    def preprocess_data(self):
        """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        print("\nğŸ”§ Preprocessing data...")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        self.feature_names = self.X_train.columns.tolist()
        
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print("âœ… Data preprocessing completed!")
        return True
    
    def train_models(self):
        """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù"""
        print("\nğŸ¤– Training multiple models...")
        
        # ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        self.models = {
            'Random Forest': RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                class_weight='balanced'
            ),
            'Gradient Boosting': GradientBoostingClassifier(
                n_estimators=150,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            ),
            'SVM': SVC(
                kernel='rbf',
                C=1.0,
                probability=True,
                random_state=42,
                class_weight='balanced'
            ),
            'Neural Network': MLPClassifier(
                hidden_layer_sizes=(100, 50),
                activation='relu',
                solver='adam',
                max_iter=500,
                random_state=42
            )
        }
        
        results = {}
        
        for name, model in self.models.items():
            print(f"\n   Training {name}...")
            
            # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
            model.fit(self.X_train_scaled, self.y_train)
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            y_pred = model.predict(self.X_test_scaled)
            y_pred_proba = model.predict_proba(self.X_test_scaled) if hasattr(model, 'predict_proba') else None
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
            accuracy = accuracy_score(self.y_test, y_pred)
            
            # Cross-validation
            cv_scores = cross_val_score(model, self.X_train_scaled, self.y_train, cv=5, scoring='accuracy')
            
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba
            }
            
            print(f"     Accuracy: {accuracy:.4f}")
            print(f"     CV Score: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        best_model_name = max(results, key=lambda x: results[x]['accuracy'])
        self.best_model = results[best_model_name]['model']
        
        print(f"\nğŸ† Best model: {best_model_name} (Accuracy: {results[best_model_name]['accuracy']:.4f})")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Random Forest
        if best_model_name == 'Random Forest':
            self.feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.best_model.feature_importances_
            }).sort_values('importance', ascending=False)
        
        self.results = results
        return results
    
    def evaluate_models(self):
        """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        print("\nğŸ“ˆ Comprehensive model evaluation...")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        # 1. Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ù‚Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
        model_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in model_names]
        cv_means = [self.results[name]['cv_mean'] for name in model_names]
        
        x = np.arange(len(model_names))
        width = 0.35
        
        axes[0].bar(x - width/2, accuracies, width, label='Test Accuracy', color='skyblue')
        axes[0].bar(x + width/2, cv_means, width, label='CV Mean', color='lightcoral')
        axes[0].set_xlabel('Models')
        axes[0].set_ylabel('Accuracy')
        axes[0].set_title('Model Comparison')
        axes[0].set_xticks(x)
        axes[0].set_xticklabels(model_names, rotation=45)
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)
        
        # 2. Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ú¯Ø± Random Forest Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨ÙˆØ¯)
        if self.feature_importance is not None:
            top_features = self.feature_importance.head(10)
            axes[1].barh(range(len(top_features)), top_features['importance'])
            axes[1].set_yticks(range(len(top_features)))
            axes[1].set_yticklabels(top_features['feature'])
            axes[1].set_xlabel('Importance')
            axes[1].set_title('Top 10 Important Features')
            axes[1].invert_yaxis()
        
        # 3. Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        best_model_name = max(self.results, key=lambda x: self.results[x]['accuracy'])
        y_pred_best = self.results[best_model_name]['y_pred']
        
        cm = confusion_matrix(self.y_test, y_pred_best)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Low', 'Medium', 'High'],
                   yticklabels=['Low', 'Medium', 'High'], ax=axes[2])
        axes[2].set_xlabel('Predicted')
        axes[2].set_ylabel('Actual')
        axes[2].set_title(f'Confusion Matrix - {best_model_name}')
        
        # 4. Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        axes[3].axis('off')
        report = classification_report(self.y_test, y_pred_best, 
                                      target_names=['Low', 'Medium', 'High'])
        axes[3].text(0, 0.5, report, fontfamily='monospace', fontsize=10, 
                    verticalalignment='center')
        axes[3].set_title('Classification Report')
        
        # 5. ROC Curve (Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù)
        if self.results[best_model_name]['y_pred_proba'] is not None:
            y_proba = self.results[best_model_name]['y_pred_proba']
            
            # One-vs-Rest ROC curves
            for i in range(3):
                fpr, tpr, _ = roc_curve((self.y_test == i).astype(int), y_proba[:, i])
                roc_auc = auc(fpr, tpr)
                axes[4].plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')
            
            axes[4].plot([0, 1], [0, 1], 'k--', alpha=0.5)
            axes[4].set_xlabel('False Positive Rate')
            axes[4].set_ylabel('True Positive Rate')
            axes[4].set_title('ROC Curves (One-vs-Rest)')
            axes[4].legend()
            axes[4].grid(True, alpha=0.3)
        
        # 6. ØªÙˆØ²ÛŒØ¹ Ø®Ø·Ø§Ù‡Ø§
        error_indices = np.where(y_pred_best != self.y_test)[0]
        if len(error_indices) > 0:
            error_counts = self.y_test.iloc[error_indices].value_counts()
            axes[5].pie(error_counts.values, labels=error_counts.index, 
                       autopct='%1.1f%%', colors=['#ff9999','#66b3ff','#99ff99'])
            axes[5].set_title('Error Distribution by Class')
        
        plt.tight_layout()
        plt.savefig('models/model_evaluation.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¹Ø¯Ø¯ÛŒ
        print("\n" + "=" * 60)
        print("FINAL MODEL PERFORMANCE")
        print("=" * 60)
        
        for name in model_names:
            result = self.results[name]
            print(f"\n{name}:")
            print(f"  Test Accuracy: {result['accuracy']:.4f}")
            print(f"  CV Accuracy:   {result['cv_mean']:.4f} (Â±{result['cv_std']:.4f})")
        
        # Ù†Ù…Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        if self.feature_importance is not None:
            print(f"\nğŸ“Š TOP 5 IMPORTANT FEATURES:")
            for idx, row in self.feature_importance.head().iterrows():
                print(f"  {row['feature']}: {row['importance']:.4f}")
    
    def save_models(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        print("\nğŸ’¾ Saving models...")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ models
        os.makedirs("models", exist_ok=True)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
        joblib.dump(self.best_model, "models/best_ocean_pollution_model.pkl")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
        for name, result in self.results.items():
            joblib.dump(result['model'], f"models/{name.lower().replace(' ', '_')}.pkl")
        
        # Ø°Ø®ÛŒØ±Ù‡ scaler
        joblib.dump(self.scaler, "models/scaler.pkl")
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        with open("models/feature_names.txt", "w") as f:
            for feature in self.feature_names:
                f.write(f"{feature}\n")
        
        print("âœ… Models saved in 'models' directory:")
        print("   - best_ocean_pollution_model.pkl")
        print("   - All individual models")
        print("   - scaler.pkl")
        print("   - feature_names.txt")
    
    def create_prediction_example(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø«Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ"""
        print("\nğŸ”® Creating prediction example...")
        
        # Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ ØªØµØ§Ø¯ÙÛŒ Ø§Ø² ØªØ³Øª
        idx = np.random.randint(0, len(self.X_test))
        sample = self.X_test.iloc[idx].values.reshape(1, -1)
        actual = self.y_test.iloc[idx]
        
        # Ù…Ù‚ÛŒØ§Ø³â€ŒØ³Ø§Ø²ÛŒ
        sample_scaled = self.scaler.transform(sample)
        
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        prediction = self.best_model.predict(sample_scaled)[0]
        probabilities = self.best_model.predict_proba(sample_scaled)[0]
        
        # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
        pollution_levels = {0: "Low", 1: "Medium", 2: "High"}
        
        print(f"\nSample prediction:")
        print(f"  Actual pollution level: {pollution_levels[actual]} ({actual})")
        print(f"  Predicted level: {pollution_levels[prediction]} ({prediction})")
        
        print(f"\nPrediction probabilities:")
        for i, prob in enumerate(probabilities):
            print(f"  {pollution_levels[i]}: {prob:.2%}")
        
        # Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§Ø¯ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        print(f"\nFeature values:")
        top_features = self.feature_importance.head(5)['feature'].tolist() if self.feature_importance is not None else self.feature_names[:5]
        
        for feature in top_features:
            if feature in self.X_test.columns:
                value = self.X_test.iloc[idx][feature]
                print(f"  {feature}: {value:.4f}")
        
        return sample, actual, prediction, probabilities

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„
    ocean_model = OceanPollutionModel()
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
    if not ocean_model.load_data():
        return
    
    # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
    ocean_model.preprocess_data()
    
    # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    ocean_model.train_models()
    
    # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
    ocean_model.evaluate_models()
    
    # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    ocean_model.save_models()
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø«Ø§Ù„
    ocean_model.create_prediction_example()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ MODEL TRAINING COMPLETED SUCCESSFULLY!")
    print("=" * 60)
    print("\nNext steps:")
    print("1. Check 'models' folder for saved models")
    print("2. Run 'predict.py' for new predictions")
    print("3. Check 'model_evaluation.png' for visualizations")

if __name__ == "__main__":
    main()
